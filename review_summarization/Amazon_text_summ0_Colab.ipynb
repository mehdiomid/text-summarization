{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Amazon_text_summ0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9GgyQAnrhj0",
        "colab_type": "code",
        "outputId": "56d208cb-3f31-410c-c0ed-ca2d78f2dd3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uns4ApCQ0139",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/gdrive/My Drive/Colab Notebooks/my_modules')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBsv_zEJv6oU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2a146c50-f10d-4a8c-c099-c61bc3992f06"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlZCwGRxWd3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "99b385cd-68e4-401e-ad84-1748497a322b"
      },
      "source": [
        "!unzip TextUtils"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  TextUtils.zip\n",
            "   creating: TextUtils/\n",
            "  inflating: TextUtils/textCleaner.py  \n",
            "  inflating: TextUtils/WordsMapping.py  \n",
            " extracting: TextUtils/__init__.py   \n",
            "   creating: TextUtils/__pycache__/\n",
            "  inflating: TextUtils/__pycache__/textCleaner.cpython-37.pyc  \n",
            "  inflating: TextUtils/__pycache__/WordsMapping.cpython-37.pyc  \n",
            "  inflating: TextUtils/__pycache__/__init__.cpython-37.pyc  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjN0YFe5r7sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-alhnobFt2Fp",
        "colab_type": "code",
        "outputId": "56c5d0d2-de54-458b-8bb6-d4bedde1899e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from TextUtils.textCleaner import text_cleaner, summary_cleaner"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSPtJ6Ps3XUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.insert(0, '/content/gdrive/My Drive/Colab Notebooks/my_modules/my_data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdULhsaToPi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('drive/My Drive/Colab Notebooks/my_modules/my_data/amazon-fine-food-reviews/Reviews.csv',nrows=100000)\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD0e12jcsIXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))\n",
        "    \n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)\n",
        "\n",
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGa_1RG-parB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text=80 #30\n",
        "max_len_summary=10 # 8\n",
        "\n",
        "max_summary_len = 10\n",
        "max_text_len = 80\n",
        "\n",
        "\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij-RWRR_quau",
        "colab_type": "text"
      },
      "source": [
        "Remember to add the START and END special tokens at the beginning and end of the summary. Here, I have chosen sostok and eostok as START and END tokens\n",
        "\n",
        "Note: Be sure that the chosen special tokens never appear in the summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kEo039_qrq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSetOFeHq9jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6xNGzysr4ir",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4-gDdWsr416",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePQIjw5CsKYT",
        "colab_type": "text"
      },
      "source": [
        "Rarewords and its Coverage\n",
        "Let us look at the proportion rare words and its total coverage in the entire text\n",
        "\n",
        "Here, I am defining the threshold to be 4 which means word whose count is below 4 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG_zF4CWsOxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "efbceef3-f3fc-4a32-eca3-d92d72352e05"
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 64.82915604819755\n",
            "Total Coverage of rare words: 1.7857911440154948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFORZf9sSc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTeA-S9smYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8680711-7cef-4d3f-f254-49e10e3e1e06"
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14216"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZbyjPObs-Rq",
        "colab_type": "text"
      },
      "source": [
        "Summary Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSs1xQLPszwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekocTPFGt_IL",
        "colab_type": "text"
      },
      "source": [
        "Rarewords and its Coverage\n",
        "Let us look at the proportion rare words and its total coverage in the entire summary\n",
        "\n",
        "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33nixloQs0H2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5c4f032b-4bbb-408d-e52d-f43e9e4a3f38"
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 76.21896983908789\n",
            "Total Coverage of rare words: 3.0542278914978884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYG_MLOJs0Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ltD0RmuP0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34cf23c2-0237-467c-d284-ff0d5917cdec"
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68918, 68918)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFWsMdq4uaL2",
        "colab_type": "text"
      },
      "source": [
        "Here, I am deleting the rows that contain only START and END tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSZ2fjlLsz9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuV70_veuf8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrB-mM7durq_",
        "colab_type": "text"
      },
      "source": [
        "Model building\n",
        "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
        "\n",
        "Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
        "\n",
        "Here, we are building a 3 stacked LSTM for the encoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPtDK1spugUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Model building\n",
        "We are finally at the model building part. But before we do that, we need to familiarize ourselves with a few terms which are required prior to building the model.\n",
        "\n",
        "Return Sequences = True: When the return sequences parameter is set to True, LSTM produces the hidden state and cell state for every timestep\n",
        "\n",
        "Return State = True: When return state = True, LSTM produces the hidden state and cell state of the last timestep only\n",
        "\n",
        "Initial State: This is used to initialize the internal states of the LSTM for the first timestep\n",
        "\n",
        "Stacked LSTM: Stacked LSTM has multiple layers of LSTM stacked on top of each other. This leads to a better representation of the sequence. I encourage you to experiment with the multiple layers of the LSTM stacked on top of each other (it’s a great way to learn this)\n",
        "\n",
        "Here, we are building a 3 stacked LSTM for the encoder:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ7pAge6uf5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "fcb3cc6f-6a08-4dfb-da8e-2edd92dc6bf1"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 100)      1421600     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    294200      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 80, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 2942)   1768142     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 6,069,042\n",
            "Trainable params: 6,069,042\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXU6wDinuf3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXhjsw6quf0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zC4JfpvvBks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "4dd7c9eb-3da7-412e-f4e4-b1b282a0dcba"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 68918 samples, validate on 7658 samples\n",
            "Epoch 1/50\n",
            "68918/68918 [==============================] - 209s 3ms/sample - loss: 2.4253 - val_loss: 2.1703\n",
            "Epoch 2/50\n",
            "68918/68918 [==============================] - 205s 3ms/sample - loss: 2.1157 - val_loss: 2.0436\n",
            "Epoch 3/50\n",
            "68918/68918 [==============================] - 201s 3ms/sample - loss: 2.0125 - val_loss: 1.9687\n",
            "Epoch 4/50\n",
            "68918/68918 [==============================] - 196s 3ms/sample - loss: 1.9471 - val_loss: 1.9341\n",
            "Epoch 5/50\n",
            "68918/68918 [==============================] - 196s 3ms/sample - loss: 1.8988 - val_loss: 1.8923\n",
            "Epoch 6/50\n",
            "68918/68918 [==============================] - 194s 3ms/sample - loss: 1.8609 - val_loss: 1.8687\n",
            "Epoch 7/50\n",
            "68918/68918 [==============================] - 195s 3ms/sample - loss: 1.8295 - val_loss: 1.8443\n",
            "Epoch 8/50\n",
            "68918/68918 [==============================] - 195s 3ms/sample - loss: 1.8011 - val_loss: 1.8283\n",
            "Epoch 9/50\n",
            "68918/68918 [==============================] - 194s 3ms/sample - loss: 1.7776 - val_loss: 1.8102\n",
            "Epoch 10/50\n",
            "68918/68918 [==============================] - 194s 3ms/sample - loss: 1.7553 - val_loss: 1.7976\n",
            "Epoch 11/50\n",
            "68918/68918 [==============================] - 193s 3ms/sample - loss: 1.7343 - val_loss: 1.7882\n",
            "Epoch 12/50\n",
            "68918/68918 [==============================] - 194s 3ms/sample - loss: 1.7165 - val_loss: 1.7787\n",
            "Epoch 13/50\n",
            "68918/68918 [==============================] - 193s 3ms/sample - loss: 1.6986 - val_loss: 1.7673\n",
            "Epoch 14/50\n",
            "68918/68918 [==============================] - 193s 3ms/sample - loss: 1.6817 - val_loss: 1.7613\n",
            "Epoch 15/50\n",
            "68918/68918 [==============================] - 193s 3ms/sample - loss: 1.6681 - val_loss: 1.7547\n",
            "Epoch 16/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6551 - val_loss: 1.7469\n",
            "Epoch 17/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6426 - val_loss: 1.7445\n",
            "Epoch 18/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6309 - val_loss: 1.7410\n",
            "Epoch 19/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6203 - val_loss: 1.7399\n",
            "Epoch 20/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6102 - val_loss: 1.7387\n",
            "Epoch 21/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.6014 - val_loss: 1.7339\n",
            "Epoch 22/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.5928 - val_loss: 1.7334\n",
            "Epoch 23/50\n",
            "68918/68918 [==============================] - 193s 3ms/sample - loss: 1.5814 - val_loss: 1.7346\n",
            "Epoch 24/50\n",
            "68918/68918 [==============================] - 192s 3ms/sample - loss: 1.5735 - val_loss: 1.7356\n",
            "Epoch 00024: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ngybqXGvB0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6622f96c-93dc-4bbc-b4e9-7752b6d01087"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTG7S9pasgpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3t0kXRhB7f5",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJATdbGl8_BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyA-s68wCIIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e7JX77HCITs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtqzPfLzCPl2",
        "colab_type": "text"
      },
      "source": [
        "Here are a few summaries generated by the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Mt7y-VCIRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "db2b8775-98b4-4763-e276-9578da5e5c12"
      },
      "source": [
        "for i in range(0,10):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: heavy soda drinker decided quit cold turkey struggle constantly mind work picked case reusable tumbler make perfect healthy substitute still cannot believe full serving fruits vegetables \n",
            "Original summary: start delicious end \n",
            "Predicted summary:  start great taste end\n",
            "\n",
            "\n",
            "Review: looking affordable cups online came across san francisco bay fog chaser yum say rich bold coffee strong flavor environmental friendly packaging excellent price highly recommend thinking \n",
            "Original summary: start excellent coffee end \n",
            "Predicted summary:  start great coffee end\n",
            "\n",
            "\n",
            "Review: truck driver kentucky searching last years every gas station come contact product literally spent weeks life looking cold chocolate nestle milk luck cannot happier finally found amazon weeks wedding none less ordered gallons reception personal consumption comment quality received \n",
            "Original summary: start wow amazing end \n",
            "Predicted summary:  start great product end\n",
            "\n",
            "\n",
            "Review: gluten free years tried many bread mixes love one husband gluten free hope everyone supports bisquick products since big brand gluten free bread pasta products rare rarely good something special came celiac disease gluten intolerance keep enjoying maybe price come offer bulk deals also wake manufacturers would happily order case much larger package make bread prefer use mix use cooking time main dishes hesitate try cannot imagine disappointed product however find less local grocery store \n",
            "Original summary: start just needs larger boxes end \n",
            "Predicted summary:  start great bread end\n",
            "\n",
            "\n",
            "Review: cookies taste exactly like samoas favorites ever unfortunately cannot find local supermarket great able order \n",
            "Original summary: start delicious end \n",
            "Predicted summary:  start best cookies ever end\n",
            "\n",
            "\n",
            "Review: maybe comparison powerbars eating long seriously delicious really good \n",
            "Original summary: start lish end \n",
            "Predicted summary:  start delicious end\n",
            "\n",
            "\n",
            "Review: although package says refrigerate opening notice first package started get moldy second fridge lasted long good soups even salads \n",
            "Original summary: start after opening end \n",
            "Predicted summary:  start great product end\n",
            "\n",
            "\n",
            "Review: glad order bounty bars amazon used get canada thanks love service fast \n",
            "Original summary: start love bounty bars end \n",
            "Predicted summary:  start great bars end\n",
            "\n",
            "\n",
            "Review: flavoring good harsh easy drink however local grocery get bottle still making much cheaper pack \n",
            "Original summary: start think might be on to something guys end \n",
            "Predicted summary:  start good but not great end\n",
            "\n",
            "\n",
            "Review: delicious still light refreshing enough pre post work drink drink flavor plain coco water sweet \n",
            "Original summary: start like light yoo hoo end \n",
            "Predicted summary:  start delicious end\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usdzQ8f3CIN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRkCVhi9ExO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "eeba2e3d-672b-46aa-8a24-849f5dd79235"
      },
      "source": [
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n",
        "\n",
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 500)      25785500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    7048000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 14096)  14110096    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 55,452,096\n",
            "Trainable params: 55,452,096\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPSKXlDzXa6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "710421d5-96ec-4895-95d3-3a7ea35d3f19"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZVnixG99N7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "663e3945-bacb-4ac1-d327-64942fd6c931"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=512, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 79516 samples, validate on 8836 samples\n",
            "Epoch 1/50\n",
            "79516/79516 [==============================] - 112s 1ms/sample - loss: 3.2024 - val_loss: 2.7387\n",
            "Epoch 2/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.7373 - val_loss: 2.5388\n",
            "Epoch 3/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.5270 - val_loss: 2.4007\n",
            "Epoch 4/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.3812 - val_loss: 2.3046\n",
            "Epoch 5/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.2633 - val_loss: 2.2383\n",
            "Epoch 6/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.1517 - val_loss: 2.2002\n",
            "Epoch 7/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 2.0549 - val_loss: 2.1758\n",
            "Epoch 8/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 1.9638 - val_loss: 2.1531\n",
            "Epoch 9/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 1.8772 - val_loss: 2.1451\n",
            "Epoch 10/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 1.7917 - val_loss: 2.1434\n",
            "Epoch 11/50\n",
            "79516/79516 [==============================] - 105s 1ms/sample - loss: 1.7068 - val_loss: 2.1537\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPYPZG-c9T3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index\n",
        "\n",
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTW4PblgKC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCMOg5hQgSms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "da7abd22-aa83-48c4-df56-df4c7dcb8871"
      },
      "source": [
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neCJ8bgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYA0b9A5gV_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3Dtc8jfges7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "8abd3525-5580-43a0-b30f-dc994f031512"
      },
      "source": [
        "for i in range(len(x_val)):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: ordered salmon thursday january received january salmon delicious wooden box nice design used store items future \n",
            "Original summary: alaska smokehouse smoked salmon \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-83ccbead9d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Original summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted summary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-3e7e103cdad6>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Sample a token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msampled_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_target_word_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampled_token_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_token\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1KQmvNUgjSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}